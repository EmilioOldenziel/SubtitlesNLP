{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, explode, count, collect_list\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import NGram, StopWordsRemover, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ, path\n",
    "environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.10:0.4.1 pyspark-shell' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark wordcount\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\", stopWords=[\".\"]) # init stopword remover\n",
    "ngram = NGram(n=2, inputCol=\"filtered_words\", outputCol=\"ngrams\")  # init ngram maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_firsts = udf(lambda l: [i[0] for i in l], ArrayType(StringType())) # take word from each list in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read xml files as df\n",
    "df_xml = spark.read \\\n",
    "  .format(\"com.databricks.spark.xml\") \\\n",
    "  .option(\"rowTag\", \"s\") \\\n",
    "  .option(\"rootTag\", \"document\") \\\n",
    "  .load(\"../subtitles/*/*/*/*/*/*/*.xml.gz\") # spark does not support recursive load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = df_xml \\\n",
    "    .withColumn(\"words\", take_firsts(col(\"w\"))) \\\n",
    "    .drop(\"_emphasis\", \"time\", \"w\") # reformat to only lists of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = stopwords_remover.transform(df_words) # remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = ngram.transform(df_words) # make ngrams with n=2 (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "|_id|               words|      filtered_words|              ngrams|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  1|[Die, muur, sal, ...|[Die, muur, sal, ...|[Die muur, muur s...|\n",
      "|  2|[Die, beveiliging...|[Die, beveiliging...|[Die beveiliging,...|\n",
      "|  3|[', n, Regime, va...|[', n, Regime, va...|[' n, n Regime, R...|\n",
      "|  4|[Daarom, is, ek, ...|[Daarom, is, ek, ...|[Daarom is, is ek...|\n",
      "|  5|[\", Ek, is, ', n,...|[\", Ek, is, ', n,...|[\" Ek, Ek is, is ...|\n",
      "|  6|[Die, WONDER, van...|[Die, WONDER, van...|[Die WONDER, WOND...|\n",
      "|  7|[-, Oos-Berlyn, 1...|[-, Oos-Berlyn, 1...|[- Oos-Berlyn, Oo...|\n",
      "|  8|  [Hello, grootseun]|  [Hello, grootseun]|   [Hello grootseun]|\n",
      "|  9|[Ek, het, nie, ty...|[Ek, het, nie, ty...|[Ek het, het nie,...|\n",
      "| 10|[Die, prof., was,...|[Die, prof., was,...|[Die prof., prof....|\n",
      "| 11|[maar, as, hy, jo...|[maar, as, hy, jo...|[maar as, as hy, ...|\n",
      "| 12|[Hy, doen, ma, ',...|[Hy, doen, ma, ',...|[Hy doen, doen ma...|\n",
      "| 13|[Jy, gooi, jou, t...|[Jy, gooi, jou, t...|[Jy gooi, gooi jo...|\n",
      "| 14|[Ek, word, stoker...|[Ek, word, stoker...|[Ek word, word st...|\n",
      "| 15|[somer, nie, ,, d...|[somer, nie, ,, d...|[somer nie, nie ,...|\n",
      "| 16|[Hou, op, daarmee...|[Hou, op, daarmee...|[Hou op, op daarm...|\n",
      "| 17|[Ek, weet, -, doo...|[Ek, weet, -, doo...|[Ek weet, weet -,...|\n",
      "| 18|[Kan, ek, by, ma,...|[Kan, ek, by, ma,...|[Kan ek, ek by, b...|\n",
      "| 19|[Jy, gee, net, om...|[Jy, gee, net, om...|[Jy gee, gee net,...|\n",
      "| 20|[Dan, moet, ek, m...|[Dan, moet, ek, m...|[Dan moet, moet e...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
